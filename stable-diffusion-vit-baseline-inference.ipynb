{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-07T02:32:34.185870Z","iopub.execute_input":"2023-04-07T02:32:34.186269Z","iopub.status.idle":"2023-04-07T02:32:37.142932Z","shell.execute_reply.started":"2023-04-07T02:32:34.186229Z","shell.execute_reply":"2023-04-07T02:32:37.141757Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    model_path = '/kaggle/input/stable-diffusion-vit-baseline-train/vit_base_patch16_224.pth'\n    model_name = 'vit_base_patch16_224'\n    input_size = 224\n    batch_size = 64","metadata":{"execution":{"iopub.status.busy":"2023-04-07T02:32:40.212430Z","iopub.execute_input":"2023-04-07T02:32:40.213578Z","iopub.status.idle":"2023-04-07T02:32:40.219185Z","shell.execute_reply.started":"2023-04-07T02:32:40.213516Z","shell.execute_reply":"2023-04-07T02:32:40.218104Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class DiffusionTestDataset(Dataset):\n    def __init__(self, images, transform):\n        self.images = images\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.images[idx])\n        image = self.transform(image)\n        return image","metadata":{"execution":{"iopub.status.busy":"2023-04-07T02:32:43.797338Z","iopub.execute_input":"2023-04-07T02:32:43.797769Z","iopub.status.idle":"2023-04-07T02:32:43.804427Z","shell.execute_reply.started":"2023-04-07T02:32:43.797737Z","shell.execute_reply":"2023-04-07T02:32:43.803200Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def predict(\n    images,\n    model_path,\n    model_name,\n    input_size,\n    batch_size\n):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    transform = transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ])\n    dataset = DiffusionTestDataset(images, transform)\n    dataloader = DataLoader(\n        dataset=dataset,\n        shuffle=False,\n        batch_size=batch_size,\n        pin_memory=True,\n        num_workers=2,\n        drop_last=False\n    )\n\n    model = timm.create_model(\n        model_name,\n        pretrained=False,\n        num_classes=384\n    )\n    state_dict = torch.load(model_path)\n    model.load_state_dict(state_dict)\n    model.to(device)\n    model.eval()\n    \n    preds = []\n    for X in tqdm(dataloader, leave=False):\n        X = X.to(device)\n\n        with torch.no_grad():\n            X_out = model(X)\n            preds.append(X_out.cpu().numpy())\n    \n    return np.vstack(preds).flatten()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T02:32:54.782889Z","iopub.execute_input":"2023-04-07T02:32:54.783600Z","iopub.status.idle":"2023-04-07T02:32:54.794630Z","shell.execute_reply.started":"2023-04-07T02:32:54.783563Z","shell.execute_reply":"2023-04-07T02:32:54.791111Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"images = list(Path('/kaggle/input/stable-diffusion-image-to-prompts/images').glob('*.png'))\nimgIds = [i.stem for i in images]\nEMBEDDING_LENGTH = 384\nimgId_eId = [\n    '_'.join(map(str, i)) for i in zip(\n        np.repeat(imgIds, EMBEDDING_LENGTH),\n        np.tile(range(EMBEDDING_LENGTH), len(imgIds)))]\n\nprompt_embeddings = predict(images, CFG.model_path, CFG.model_name, CFG.input_size, CFG.batch_size)\nsubmission = pd.DataFrame(\n    index=imgId_eId,\n    data=prompt_embeddings,\n    columns=['val']\n).rename_axis('imgId_eId')\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T02:33:03.756860Z","iopub.execute_input":"2023-04-07T02:33:03.757245Z","iopub.status.idle":"2023-04-07T02:33:14.694616Z","shell.execute_reply.started":"2023-04-07T02:33:03.757213Z","shell.execute_reply":"2023-04-07T02:33:14.693559Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf96c126226649729e5a829d7c3b852e"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}