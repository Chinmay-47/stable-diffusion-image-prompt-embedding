{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nfrom scipy import spatial\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torchvision import transforms\nimport timm\nfrom timm.utils import AverageMeter\nimport sys\nsys.path.append('../input/sentence-transformers-222/sentence-transformers')\nfrom sentence_transformers import SentenceTransformer\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T02:28:06.191728Z","iopub.execute_input":"2023-04-07T02:28:06.192157Z","iopub.status.idle":"2023-04-07T02:28:19.544648Z","shell.execute_reply.started":"2023-04-07T02:28:06.192120Z","shell.execute_reply":"2023-04-07T02:28:19.543541Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    model_name = 'vit_base_patch16_224'\n    input_size = 224\n    batch_size = 64\n    num_epochs = 3\n    lr = 1e-4\n    seed = 42","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:04:14.023119Z","iopub.execute_input":"2023-04-03T14:04:14.024338Z","iopub.status.idle":"2023-04-03T14:04:14.029815Z","shell.execute_reply.started":"2023-04-03T14:04:14.024288Z","shell.execute_reply":"2023-04-03T14:04:14.028854Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\n\nseed_everything(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:04:14.031677Z","iopub.execute_input":"2023-04-03T14:04:14.032507Z","iopub.status.idle":"2023-04-03T14:04:14.107274Z","shell.execute_reply.started":"2023-04-03T14:04:14.032471Z","shell.execute_reply":"2023-04-03T14:04:14.106323Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class DiffusionDataset(Dataset):\n    def __init__(self, df, transform):\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image = Image.open(row['filepath'])\n        image = self.transform(image)\n        prompt = row['prompt']\n        return image, prompt\n\n\nclass DiffusionCollator:\n    def __init__(self):\n        self.st_model = SentenceTransformer(\n            '/kaggle/input/sentence-transformers-222/all-MiniLM-L6-v2',\n            device='cpu'\n        )\n    \n    def __call__(self, batch):\n        images, prompts = zip(*batch)\n        images = torch.stack(images)\n        prompt_embeddings = self.st_model.encode(\n            prompts, \n            show_progress_bar=False, \n            convert_to_tensor=True\n        )\n        return images, prompt_embeddings\n    \n    \ndef get_dataloaders(\n    trn_df,\n    val_df,\n    input_size,\n    batch_size\n):\n    transform = transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ])\n\n    trn_dataset = DiffusionDataset(trn_df, transform)\n    val_dataset = DiffusionDataset(val_df, transform)\n    collator = DiffusionCollator()\n    \n    dataloaders = {}\n    dataloaders['train'] = DataLoader(\n        dataset=trn_dataset,\n        shuffle=True,\n        batch_size=batch_size,\n        pin_memory=True,\n        num_workers=2,\n        drop_last=True,\n        collate_fn=collator\n    )\n    dataloaders['val'] = DataLoader(\n        dataset=val_dataset,\n        shuffle=False,\n        batch_size=batch_size,\n        pin_memory=True,\n        num_workers=2,\n        drop_last=False,\n        collate_fn=collator\n    )\n    return dataloaders","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:04:14.110573Z","iopub.execute_input":"2023-04-03T14:04:14.110893Z","iopub.status.idle":"2023-04-03T14:04:14.122725Z","shell.execute_reply.started":"2023-04-03T14:04:14.110868Z","shell.execute_reply":"2023-04-03T14:04:14.121695Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def cosine_similarity(y_trues, y_preds):\n    return np.mean([\n        1 - spatial.distance.cosine(y_true, y_pred) \n        for y_true, y_pred in zip(y_trues, y_preds)\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:04:14.126831Z","iopub.execute_input":"2023-04-03T14:04:14.127469Z","iopub.status.idle":"2023-04-03T14:04:14.135293Z","shell.execute_reply.started":"2023-04-03T14:04:14.127443Z","shell.execute_reply":"2023-04-03T14:04:14.134298Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def train(\n    trn_df,\n    val_df,\n    model_name,\n    input_size,\n    batch_size,\n    num_epochs,\n    lr\n):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    dataloaders = get_dataloaders(\n        trn_df,\n        val_df,\n        input_size,\n        batch_size\n    )\n\n    model = timm.create_model(\n        model_name,\n        pretrained=True,\n        num_classes=384\n    )\n    model.set_grad_checkpointing()\n    model.to(device)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n\n    ttl_iters = num_epochs * len(dataloaders['train'])\n    scheduler = CosineAnnealingLR(optimizer, T_max=ttl_iters, eta_min=1e-6)\n    criterion = nn.CosineEmbeddingLoss()\n    \n    best_score = -1.0\n\n    for epoch in range(num_epochs):\n        train_meters = {\n            'loss': AverageMeter(),\n            'cos': AverageMeter(),\n        }\n        model.train()\n        for X, y in tqdm(dataloaders['train'], leave=False):\n            X, y = X.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            X_out = model(X)\n            target = torch.ones(X.size(0)).to(device)\n            loss = criterion(X_out, y, target)\n            loss.backward()\n\n            optimizer.step()\n            scheduler.step()\n\n            trn_loss = loss.item()\n            trn_cos = cosine_similarity(\n                X_out.detach().cpu().numpy(), \n                y.detach().cpu().numpy()\n            )\n\n            train_meters['loss'].update(trn_loss, n=X.size(0))\n            train_meters['cos'].update(trn_cos, n=X.size(0))\n\n        print('Epoch {:d} / trn/loss={:.4f}, trn/cos={:.4f}'.format(\n            epoch + 1,\n            train_meters['loss'].avg,\n            train_meters['cos'].avg))\n\n        val_meters = {\n            'loss': AverageMeter(),\n            'cos': AverageMeter(),\n        }\n        model.eval()\n        for X, y in tqdm(dataloaders['val'], leave=False):\n            X, y = X.to(device), y.to(device)\n\n            with torch.no_grad():\n                X_out = model(X)\n                target = torch.ones(X.size(0)).to(device)\n                loss = criterion(X_out, y, target)\n\n                val_loss = loss.item()\n                val_cos = cosine_similarity(\n                    X_out.detach().cpu().numpy(), \n                    y.detach().cpu().numpy()\n                )\n\n            val_meters['loss'].update(val_loss, n=X.size(0))\n            val_meters['cos'].update(val_cos, n=X.size(0))\n\n        print('Epoch {:d} / val/loss={:.4f}, val/cos={:.4f}'.format(\n            epoch + 1,\n            val_meters['loss'].avg,\n            val_meters['cos'].avg))\n        \n        if val_meters['cos'].avg > best_score:\n            best_score = val_meters['cos'].avg\n            torch.save(model.state_dict(), f'{model_name}.pth')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:04:14.136769Z","iopub.execute_input":"2023-04-03T14:04:14.137249Z","iopub.status.idle":"2023-04-03T14:04:14.153832Z","shell.execute_reply.started":"2023-04-03T14:04:14.137214Z","shell.execute_reply":"2023-04-03T14:04:14.152839Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/diffusiondb-data-cleansing/diffusiondb.csv')\ntrn_df, val_df = train_test_split(df, test_size=0.1, random_state=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:04:14.155229Z","iopub.execute_input":"2023-04-03T14:04:14.155574Z","iopub.status.idle":"2023-04-03T14:04:14.896374Z","shell.execute_reply.started":"2023-04-03T14:04:14.155540Z","shell.execute_reply":"2023-04-03T14:04:14.895347Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train(trn_df, val_df, CFG.model_name, CFG.input_size, CFG.batch_size, CFG.num_epochs, CFG.lr)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T14:04:14.897615Z","iopub.execute_input":"2023-04-03T14:04:14.898014Z","iopub.status.idle":"2023-04-03T18:23:10.841049Z","shell.execute_reply.started":"2023-04-03T14:04:14.897978Z","shell.execute_reply":"2023-04-03T18:23:10.839273Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2170 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1 / trn/loss=0.5013, trn/cos=0.4987\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/242 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1 / val/loss=0.4636, val/cos=0.5364\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2170 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2 / trn/loss=0.4279, trn/cos=0.5721\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/242 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2 / val/loss=0.4398, val/cos=0.5602\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2170 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3 / trn/loss=0.3802, trn/cos=0.6198\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/242 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3 / val/loss=0.4370, val/cos=0.5630\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}